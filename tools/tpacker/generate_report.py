# Copyright (C) 2025 listenai Co.Ltd
# All rights reserved.
# Created by leifang on 2022.09.31

import os
import datetime
from typing import Dict
from glob import glob
from .enum_defines import MemType, ALIGN16, Colors

def clean_invalid_files():
    """Clean up invalid files in the temporary directory."""
    temp_dir = os.path.join(os.getcwd(), 'model.ignore')
    if os.path.exists(temp_dir):
        for file_path in glob(os.path.join(temp_dir, '*')):
            if os.path.isfile(file_path):
                os.unlink(file_path)

def generate_memory_report(model: str, memory_plan: Dict):
    """Generate a memory usage report for the model.
    
    Args:
        model (str): Path to the ONNX model file
        memory_plan (Dict): Memory allocation plan containing tensor contexts
    """
    file_name = model.split('/')[-1]
    assert file_name.endswith(".onnx"), "Input must be an ONNX model file"
    report_file = f"./workspace/{file_name[:-5]}/{file_name[:-5]}_memory_report.txt"
    
    with open(report_file, "w") as fp:
        fp.write(f"Generated by {os.getlogin()} in {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        fp.write("=" * 126 + "\n")
        fp.write(f"|{'*' * 52} memory plan result {'*' * 52}|\n")
        fp.write("=" * 126 + "\n\n")
        
        memory_types = set()
        for ctx in memory_plan.entry_ctx_list:
            tensor = ctx.entry.tensor
            if tensor and tensor.data is not None:
                memory_types.add(tensor.mem_type)
        
        for mem_type in memory_types:
            params_buff = b""
            for ctx in memory_plan.entry_ctx_list:
                tensor = ctx.entry.tensor
                if tensor and tensor.data is not None and tensor.mem_type == mem_type:
                    t = tensor.data
                    offset = ALIGN16(len(t.tobytes()))
                    params_buff += t.tobytes() + b"\0" * (offset - len(t.tobytes()))
            
            fp.write(f"|{mem_type:<48} total size: {len(params_buff):<64}|\n")
            fp.write("-" * 126 + "\n")
            fp.write(f"|{len(params_buff)} (-1) " + " " * 3 + "|\n")
            fp.write("-" * 126 + "\n")
            fp.write("|tensor name" + " " * 40 + "mem id" + " " * 10 + 
                     "life begin" + " " * 6 + "life end" + " " * 13 + 
                     "tensor size" + " " * 9 + "|\n")
            fp.write("-" * 126 + "\n")
            
            for ctx in memory_plan.entry_ctx_list:
                tensor = ctx.entry.tensor
                if tensor and tensor.data is not None and tensor.mem_type == mem_type:
                    life_end = "INF" if ctx.life_end == 100000000000 else ctx.life_end
                    fp.write(f"|{ctx.entry.name:<50} {ctx.mem_id:<15} {ctx.life_begin:<15} {life_end:<20} {ctx.nbytes:<20}|\n")
            fp.write("-" * 126 + "\n\n")
        
        for k, v in memory_plan.mem_sizes.items():
            runtime_size = sum(v)
            fp.write("-" * 126 + "\n")
            fp.write(f"|MemType.{MemType(k).name:<50} total size: {runtime_size:<54}|\n")
            fp.write("-" * 126 + "\n")
            fp.write(" | ".join([f"{size} ({i})" for i, size in enumerate(v)]) + " |\n")
            fp.write("-" * 126 + "\n")
            fp.write("|tensor name" + " " * 40 + "mem id" + " " * 10 + 
                     "life begin" + " " * 6 + "life end" + " " * 13 + 
                     "tensor size" + " " * 9 + "|\n")
            fp.write("-" * 126 + "\n")
            
            for ctx in memory_plan.entry_ctx_list:
                tensor = ctx.entry.tensor
                if tensor.mem_type.value == k and tensor.data is None:
                    fp.write(f"|{ctx.entry.name:<50} {ctx.mem_id:<15} {ctx.life_begin:<15} {ctx.life_end:<20} {ctx.nbytes:<20}|\n")
            fp.write("-" * 126 + "\n")
    
    print(f"{Colors.GREEN}6.1 memory report generate passed{Colors.RESET}")

__all__ = ["clean_invalid_files", "generate_memory_report"]